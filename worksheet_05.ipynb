{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Isaac Chan\n",
    "UID: U93997706\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assign each data point to the nearest centroid:\n",
    "    assignments: c1, c1, c2, c2, c2, c2, c2\n",
    "2. Calculate the new centroids by finding the average of all the data points assigned to each centroid:\n",
    "    c1 = 0.25   c2 = 4.6\n",
    "3. Repeat assignments with new centroids:\n",
    "    assignments: c1, c1, c1, c1, c2, c2, c2,\n",
    "4. Calculate new centroids:\n",
    "    c1 = 1      c2 = 6.5\n",
    "5. Check for convergence:\n",
    "    If the centroids do not change (or the change is below a certain threshold), the algorithm has converged. In this case, the centroids have changed, so we would repeat the assignment and update steps. However, if we continue the iterations, we'll find that the centroids stabilize at 1 and 6.5.\n",
    "    So final centroids are 1 and 6.5 and final assignments are c1, c1, c1, c1, c2, c2, c2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function for KMeans measures how spread out the data points are within each cluster. It calculates the tightness of the data points in each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KMeans algorithm can produce different solutions on the same dataset due to its sensitivity to initial centroid placements and the possibility of converging to local minima. Other factors like data order, distance metrics, and the presence of noise or outliers can also influence the clustering outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Lloyd's Algorithm always converges, but it might converge to a local minimum rather than a global minimum. This is because each iteration of the algorithm reduces the cost function, ensuring no infinite loops, but the final solution can be dependent on the initial centroid placements."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "\n",
    "    def lloyds(self):\n",
    "        # Randomly initialize the centroids\n",
    "        centers = self.data[np.random.choice(self.data.shape[0], self.k, replace=False)]\n",
    "        \n",
    "        while True:\n",
    "            # Assignment step\n",
    "            distances = np.linalg.norm(self.data[:, np.newaxis] - centers, axis=2)\n",
    "            new_assignment = np.argmin(distances, axis=1)\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.array_equal(new_assignment, self.assignment):\n",
    "                break\n",
    "\n",
    "            self.assignment = new_assignment\n",
    "\n",
    "            # Update step\n",
    "            new_centers = np.array([self.data[self.assignment == i].mean(axis=0) for i in range(self.k)])\n",
    "\n",
    "            # Take a snapshot for visualization\n",
    "            self.snap(new_centers)\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.array_equal(new_centers, centers):\n",
    "                break\n",
    "\n",
    "            centers = new_centers\n",
    "\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
